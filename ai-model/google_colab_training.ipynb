{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd42b50",
   "metadata": {},
   "source": [
    "# BaggageLens - Siamese Network Training (Google Colab)\n",
    "\n",
    "This notebook trains the CNN + Siamese network for luggage image matching.\n",
    "\n",
    "**Steps:**\n",
    "1. Install dependencies\n",
    "2. Prepare dataset\n",
    "3. Train model with GPU\n",
    "4. Save model\n",
    "5. Download model files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16d0c7",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.14.0 numpy opencv-python Pillow scikit-learn scipy -q\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c3005",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f3165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f95b85",
   "metadata": {},
   "source": [
    "## Step 3: Define CNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2148d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_encoder(input_shape=(256, 256, 3)):\n",
    "    \"\"\"Create CNN encoder for feature extraction\"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    return keras.Model(inputs, x, name='encoder')\n",
    "\n",
    "print(\"âœ… CNN encoder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fdfb8e",
   "metadata": {},
   "source": [
    "## Step 4: Define L2 Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15501237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Distance(layers.Layer):\n",
    "    \"\"\"Custom layer for Euclidean distance\"\"\"\n",
    "    def call(self, x):\n",
    "        x1, x2 = x\n",
    "        return tf.math.sqrt(tf.reduce_sum(tf.square(x1 - x2), axis=1, keepdims=True))\n",
    "\n",
    "print(\"âœ… L2Distance layer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da38629",
   "metadata": {},
   "source": [
    "## Step 5: Create Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_siamese_network(input_shape=(256, 256, 3)):\n",
    "    \"\"\"Create full Siamese network for image comparison\"\"\"\n",
    "    encoder = create_cnn_encoder(input_shape)\n",
    "    \n",
    "    # Input layers for two images\n",
    "    input_1 = keras.Input(shape=input_shape)\n",
    "    input_2 = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encode both images\n",
    "    encoded_1 = encoder(input_1)\n",
    "    encoded_2 = encoder(input_2)\n",
    "    \n",
    "    # Calculate distance\n",
    "    distance = L2Distance()([encoded_1, encoded_2])\n",
    "    \n",
    "    # Normalize distance to 0-1 range (similarity)\n",
    "    similarity = layers.Lambda(lambda x: 1 / (1 + x))(distance)\n",
    "    \n",
    "    return keras.Model([input_1, input_2], similarity, name='siamese_network')\n",
    "\n",
    "model = create_siamese_network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800980f1",
   "metadata": {},
   "source": [
    "## Step 6: Generate Sample Training Data\n",
    "\n",
    "**For production:** Upload your dataset folder with lost/ and found/ subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddad5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample training data for demo\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Generate synthetic training pairs\n",
    "def generate_sample_data(num_samples=100):\n",
    "    \"\"\"Generate synthetic image pairs for training\"\"\"\n",
    "    X1 = np.random.rand(num_samples, 256, 256, 3).astype(np.float32)\n",
    "    X2 = np.random.rand(num_samples, 256, 256, 3).astype(np.float32)\n",
    "    \n",
    "    # Create labels: 1 for similar pairs, 0 for dissimilar\n",
    "    y = np.random.randint(0, 2, num_samples).astype(np.float32)\n",
    "    \n",
    "    # For similar pairs, make images more similar\n",
    "    for i in range(num_samples):\n",
    "        if y[i] == 1:\n",
    "            X2[i] = X1[i] + np.random.rand(256, 256, 3) * 0.1  # Add small noise\n",
    "    \n",
    "    return X1, X2, y\n",
    "\n",
    "print(\"Generating sample training data...\")\n",
    "X1_train, X2_train, y_train = generate_sample_data(500)\n",
    "X1_val, X2_val, y_val = generate_sample_data(100)\n",
    "\n",
    "print(f\"Training data: {X1_train.shape}\")\n",
    "print(f\"Validation data: {X1_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a14708",
   "metadata": {},
   "source": [
    "## Step 7: Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"âœ… Model compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8b36e",
   "metadata": {},
   "source": [
    "## Step 8: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    [X1_train, X2_train], y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=([X1_val, X2_val], y_val),\n",
    "    verbose=1\n",
    ")\n",
    "print(\"âœ… Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd164ad9",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate([X1_val, X2_val], y_val, verbose=0)\n",
    "print(f\"\\nðŸ“Š Model Performance:\")\n",
    "print(f\"   Loss: {loss:.4f}\")\n",
    "print(f\"   Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5132313",
   "metadata": {},
   "source": [
    "## Step 10: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ed99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the full model\n",
    "model.save('models/siamese_model.h5')\n",
    "print(\"âœ… Model saved as siamese_model.h5\")\n",
    "\n",
    "# Also save in TensorFlow SavedModel format (recommended)\n",
    "model.save('models/siamese_model')\n",
    "print(\"âœ… Model saved in TensorFlow SavedModel format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301ea8b",
   "metadata": {},
   "source": [
    "## Step 11: Download Model Files\n",
    "\n",
    "Run the cell below to download the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the .h5 model\n",
    "print(\"Downloading model files...\")\n",
    "files.download('models/siamese_model.h5')\n",
    "print(\"âœ… Downloaded: siamese_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61268c73",
   "metadata": {},
   "source": [
    "## Instructions for Local Use\n",
    "\n",
    "1. Download the trained model from Colab\n",
    "2. Place `siamese_model.h5` in the `models/` folder\n",
    "3. The API will automatically load it\n",
    "4. Run: `python api.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
